{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "included-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = 'nkondapa-ee148b-data'\n",
    "prefix = 'sagemaker/pytorch-mnist'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "respective-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nkondapa-ee148b-data arn:aws:iam::651564860437:role/service-role/AmazonSageMaker-ExecutionRole-20210407T145634\n",
      "/home/ec2-user/SageMaker/ee148b_sagemaker_mnist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(bucket, role)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acute-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='main.py',\n",
    "                    source_dir='./',\n",
    "                    framework_version='1.8.0',\n",
    "                    role=role,\n",
    "                    py_version='py3',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.g4dn.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 4,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "racial-technology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://nkondapa-ee148b-data/mnist_data/\n"
     ]
    }
   ],
   "source": [
    "print(f's3://{bucket}/mnist_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "found-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 18:22:44 Starting - Starting the training job...\n",
      "2021-04-21 18:23:12 Starting - Launching requested ML instancesProfilerReport-1619029364: InProgress\n",
      "......\n",
      "2021-04-21 18:24:12 Starting - Preparing the instances for training.........\n",
      "2021-04-21 18:25:36 Downloading - Downloading input data...\n",
      "2021-04-21 18:26:12 Training - Downloading the training image.................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-04-21 18:28:58,112 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-04-21 18:28:58,132 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-04-21 18:29:04,351 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-04-21 18:29:04,787 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses==0.8 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\n",
      "2021-04-21 18:29:13 Training - Training image download completed. Training in progress.\u001b[34mCollecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting Pillow==8.2.0\n",
      "  Downloading Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting torch==1.8.1\n",
      "  Downloading torch-1.8.1-cp36-cp36m-manylinux1_x86_64.whl (804.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting torchvision==0.9.1\n",
      "  Downloading torchvision-0.9.1-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions==3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, torch, Pillow, torchvision\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.0\n",
      "    Uninstalling torch-1.8.0:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled torch-1.8.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.1.2\n",
      "    Uninstalling Pillow-8.1.2:\n",
      "      Successfully uninstalled Pillow-8.1.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.9.0\n",
      "    Uninstalling torchvision-0.9.0:\n",
      "      Successfully uninstalled torchvision-0.9.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed Pillow-8.2.0 numpy-1.19.5 torch-1.8.1 torchvision-0.9.1\n",
      "\u001b[0m\n",
      "\u001b[34m2021-04-21 18:29:44,283 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 4\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-04-21-18-22-43-971\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-651564860437/pytorch-training-2021-04-21-18-22-43-971/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":4}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-651564860437/pytorch-training-2021-04-21-18-22-43-971/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":4},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-04-21-18-22-43-971\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-651564860437/pytorch-training-2021-04-21-18-22-43-971/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"4\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 main.py --epochs 4\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/60000 (0%)]#011Loss: 2.331472\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [640/60000 (1%)]#011Loss: 1.062340\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [1280/60000 (2%)]#011Loss: 1.013392\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [1920/60000 (3%)]#011Loss: 0.579085\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [2560/60000 (4%)]#011Loss: 0.620085\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [3200/60000 (5%)]#011Loss: 0.415884\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [3840/60000 (6%)]#011Loss: 0.278938\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [4480/60000 (7%)]#011Loss: 0.312672\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [5120/60000 (9%)]#011Loss: 0.406086\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [5760/60000 (10%)]#011Loss: 0.339390\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)]#011Loss: 0.463849\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [7040/60000 (12%)]#011Loss: 0.148826\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [7680/60000 (13%)]#011Loss: 0.235661\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [8320/60000 (14%)]#011Loss: 0.182561\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [8960/60000 (15%)]#011Loss: 0.228552\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [9600/60000 (16%)]#011Loss: 0.212143\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [10240/60000 (17%)]#011Loss: 0.209838\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [10880/60000 (18%)]#011Loss: 0.319318\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [11520/60000 (19%)]#011Loss: 0.243411\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12160/60000 (20%)]#011Loss: 0.130829\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)]#011Loss: 0.321399\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [13440/60000 (22%)]#011Loss: 0.428393\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [14080/60000 (23%)]#011Loss: 0.134295\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [14720/60000 (25%)]#011Loss: 0.129052\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [15360/60000 (26%)]#011Loss: 0.033610\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [16000/60000 (27%)]#011Loss: 0.147278\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [16640/60000 (28%)]#011Loss: 0.088086\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [17280/60000 (29%)]#011Loss: 0.263389\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [17920/60000 (30%)]#011Loss: 0.128052\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [18560/60000 (31%)]#011Loss: 0.153165\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)]#011Loss: 0.107667\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19840/60000 (33%)]#011Loss: 0.055109\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [20480/60000 (34%)]#011Loss: 0.073212\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [21120/60000 (35%)]#011Loss: 0.298644\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [21760/60000 (36%)]#011Loss: 0.090432\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [22400/60000 (37%)]#011Loss: 0.199685\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [23040/60000 (38%)]#011Loss: 0.125713\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [23680/60000 (39%)]#011Loss: 0.156547\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [24320/60000 (41%)]#011Loss: 0.162171\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [24960/60000 (42%)]#011Loss: 0.066490\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)]#011Loss: 0.172989\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [26240/60000 (44%)]#011Loss: 0.053440\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [26880/60000 (45%)]#011Loss: 0.151322\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [27520/60000 (46%)]#011Loss: 0.088744\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [28160/60000 (47%)]#011Loss: 0.092907\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [28800/60000 (48%)]#011Loss: 0.203204\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [29440/60000 (49%)]#011Loss: 0.327307\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [30080/60000 (50%)]#011Loss: 0.049841\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [30720/60000 (51%)]#011Loss: 0.063794\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [31360/60000 (52%)]#011Loss: 0.102069\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)]#011Loss: 0.058345\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32640/60000 (54%)]#011Loss: 0.037818\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [33280/60000 (55%)]#011Loss: 0.055110\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [33920/60000 (57%)]#011Loss: 0.042665\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [34560/60000 (58%)]#011Loss: 0.250420\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [35200/60000 (59%)]#011Loss: 0.084288\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [35840/60000 (60%)]#011Loss: 0.061736\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [36480/60000 (61%)]#011Loss: 0.174719\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [37120/60000 (62%)]#011Loss: 0.167037\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [37760/60000 (63%)]#011Loss: 0.152530\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)]#011Loss: 0.139949\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [39040/60000 (65%)]#011Loss: 0.021084\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [39680/60000 (66%)]#011Loss: 0.210906\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [40320/60000 (67%)]#011Loss: 0.199062\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [40960/60000 (68%)]#011Loss: 0.138184\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [41600/60000 (69%)]#011Loss: 0.272571\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [42240/60000 (70%)]#011Loss: 0.046222\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [42880/60000 (71%)]#011Loss: 0.178667\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [43520/60000 (72%)]#011Loss: 0.063989\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44160/60000 (74%)]#011Loss: 0.015847\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)]#011Loss: 0.152296\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [45440/60000 (76%)]#011Loss: 0.098187\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [46080/60000 (77%)]#011Loss: 0.090747\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [46720/60000 (78%)]#011Loss: 0.116184\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [47360/60000 (79%)]#011Loss: 0.042578\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [48000/60000 (80%)]#011Loss: 0.221529\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [48640/60000 (81%)]#011Loss: 0.072514\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [49280/60000 (82%)]#011Loss: 0.061549\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [49920/60000 (83%)]#011Loss: 0.049024\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [50560/60000 (84%)]#011Loss: 0.162899\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)]#011Loss: 0.055648\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51840/60000 (86%)]#011Loss: 0.043057\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [52480/60000 (87%)]#011Loss: 0.066530\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [53120/60000 (88%)]#011Loss: 0.102838\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [53760/60000 (90%)]#011Loss: 0.135414\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [54400/60000 (91%)]#011Loss: 0.181759\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [55040/60000 (92%)]#011Loss: 0.075002\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [55680/60000 (93%)]#011Loss: 0.118428\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [56320/60000 (94%)]#011Loss: 0.071582\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [56960/60000 (95%)]#011Loss: 0.174102\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)]#011Loss: 0.031155\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [58240/60000 (97%)]#011Loss: 0.123470\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [58880/60000 (98%)]#011Loss: 0.139225\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [59520/60000 (99%)]#011Loss: 0.099780\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0554, Accuracy: 9835/10000 (98%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/60000 (0%)]#011Loss: 0.071209\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [640/60000 (1%)]#011Loss: 0.160604\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [1280/60000 (2%)]#011Loss: 0.107533\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [1920/60000 (3%)]#011Loss: 0.050487\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [2560/60000 (4%)]#011Loss: 0.042646\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [3200/60000 (5%)]#011Loss: 0.131466\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [3840/60000 (6%)]#011Loss: 0.058006\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [4480/60000 (7%)]#011Loss: 0.083360\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [5120/60000 (9%)]#011Loss: 0.037124\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [5760/60000 (10%)]#011Loss: 0.010140\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/60000 (11%)]#011Loss: 0.301808\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [7040/60000 (12%)]#011Loss: 0.066700\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [7680/60000 (13%)]#011Loss: 0.119364\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [8320/60000 (14%)]#011Loss: 0.047627\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [8960/60000 (15%)]#011Loss: 0.074469\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [9600/60000 (16%)]#011Loss: 0.023658\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [10240/60000 (17%)]#011Loss: 0.025561\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [10880/60000 (18%)]#011Loss: 0.034917\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [11520/60000 (19%)]#011Loss: 0.096767\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12160/60000 (20%)]#011Loss: 0.082405\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/60000 (21%)]#011Loss: 0.085956\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [13440/60000 (22%)]#011Loss: 0.011478\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [14080/60000 (23%)]#011Loss: 0.053260\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [14720/60000 (25%)]#011Loss: 0.035264\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [15360/60000 (26%)]#011Loss: 0.174731\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [16000/60000 (27%)]#011Loss: 0.098473\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [16640/60000 (28%)]#011Loss: 0.019105\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [17280/60000 (29%)]#011Loss: 0.002880\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [17920/60000 (30%)]#011Loss: 0.009822\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [18560/60000 (31%)]#011Loss: 0.112226\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/60000 (32%)]#011Loss: 0.052331\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19840/60000 (33%)]#011Loss: 0.049693\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [20480/60000 (34%)]#011Loss: 0.075938\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [21120/60000 (35%)]#011Loss: 0.271231\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [21760/60000 (36%)]#011Loss: 0.040938\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [22400/60000 (37%)]#011Loss: 0.126948\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [23040/60000 (38%)]#011Loss: 0.125700\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [23680/60000 (39%)]#011Loss: 0.123693\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [24320/60000 (41%)]#011Loss: 0.028255\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [24960/60000 (42%)]#011Loss: 0.020586\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [25600/60000 (43%)]#011Loss: 0.072213\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [26240/60000 (44%)]#011Loss: 0.105682\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [26880/60000 (45%)]#011Loss: 0.031355\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [27520/60000 (46%)]#011Loss: 0.038471\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [28160/60000 (47%)]#011Loss: 0.027835\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [28800/60000 (48%)]#011Loss: 0.203426\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [29440/60000 (49%)]#011Loss: 0.035172\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [30080/60000 (50%)]#011Loss: 0.141429\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [30720/60000 (51%)]#011Loss: 0.166219\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [31360/60000 (52%)]#011Loss: 0.171808\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)]#011Loss: 0.120286\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32640/60000 (54%)]#011Loss: 0.006646\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [33280/60000 (55%)]#011Loss: 0.015033\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [33920/60000 (57%)]#011Loss: 0.049522\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [34560/60000 (58%)]#011Loss: 0.093672\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [35200/60000 (59%)]#011Loss: 0.133575\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [35840/60000 (60%)]#011Loss: 0.039169\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [36480/60000 (61%)]#011Loss: 0.104673\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [37120/60000 (62%)]#011Loss: 0.040373\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [37760/60000 (63%)]#011Loss: 0.174142\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [38400/60000 (64%)]#011Loss: 0.077398\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [39040/60000 (65%)]#011Loss: 0.045677\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [39680/60000 (66%)]#011Loss: 0.011958\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [40320/60000 (67%)]#011Loss: 0.066716\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [40960/60000 (68%)]#011Loss: 0.091884\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [41600/60000 (69%)]#011Loss: 0.039400\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [42240/60000 (70%)]#011Loss: 0.020195\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [42880/60000 (71%)]#011Loss: 0.163158\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [43520/60000 (72%)]#011Loss: 0.013324\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44160/60000 (74%)]#011Loss: 0.012995\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [44800/60000 (75%)]#011Loss: 0.009582\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [45440/60000 (76%)]#011Loss: 0.104777\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [46080/60000 (77%)]#011Loss: 0.040626\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [46720/60000 (78%)]#011Loss: 0.017526\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [47360/60000 (79%)]#011Loss: 0.067676\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [48000/60000 (80%)]#011Loss: 0.011223\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [48640/60000 (81%)]#011Loss: 0.027890\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [49280/60000 (82%)]#011Loss: 0.025886\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [49920/60000 (83%)]#011Loss: 0.064931\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [50560/60000 (84%)]#011Loss: 0.015850\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51200/60000 (85%)]#011Loss: 0.132665\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [51840/60000 (86%)]#011Loss: 0.022356\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [52480/60000 (87%)]#011Loss: 0.090664\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [53120/60000 (88%)]#011Loss: 0.077543\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [53760/60000 (90%)]#011Loss: 0.021517\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [54400/60000 (91%)]#011Loss: 0.142557\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [55040/60000 (92%)]#011Loss: 0.300666\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [55680/60000 (93%)]#011Loss: 0.107948\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [56320/60000 (94%)]#011Loss: 0.006728\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [56960/60000 (95%)]#011Loss: 0.036110\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [57600/60000 (96%)]#011Loss: 0.006342\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [58240/60000 (97%)]#011Loss: 0.034436\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [58880/60000 (98%)]#011Loss: 0.115903\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [59520/60000 (99%)]#011Loss: 0.101931\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0391, Accuracy: 9875/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/60000 (0%)]#011Loss: 0.045276\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [640/60000 (1%)]#011Loss: 0.063619\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [1280/60000 (2%)]#011Loss: 0.135716\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [1920/60000 (3%)]#011Loss: 0.125475\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [2560/60000 (4%)]#011Loss: 0.048939\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [3200/60000 (5%)]#011Loss: 0.014667\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [3840/60000 (6%)]#011Loss: 0.016179\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [4480/60000 (7%)]#011Loss: 0.011107\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [5120/60000 (9%)]#011Loss: 0.063600\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [5760/60000 (10%)]#011Loss: 0.030365\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [6400/60000 (11%)]#011Loss: 0.005285\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [7040/60000 (12%)]#011Loss: 0.055027\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [7680/60000 (13%)]#011Loss: 0.030576\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [8320/60000 (14%)]#011Loss: 0.079519\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [8960/60000 (15%)]#011Loss: 0.071560\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [9600/60000 (16%)]#011Loss: 0.060680\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [10240/60000 (17%)]#011Loss: 0.078001\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [10880/60000 (18%)]#011Loss: 0.017958\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [11520/60000 (19%)]#011Loss: 0.152945\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [12160/60000 (20%)]#011Loss: 0.173490\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [12800/60000 (21%)]#011Loss: 0.029178\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [13440/60000 (22%)]#011Loss: 0.010137\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [14080/60000 (23%)]#011Loss: 0.011367\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [14720/60000 (25%)]#011Loss: 0.055952\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [15360/60000 (26%)]#011Loss: 0.157657\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [16000/60000 (27%)]#011Loss: 0.045396\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [16640/60000 (28%)]#011Loss: 0.157048\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [17280/60000 (29%)]#011Loss: 0.030480\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [17920/60000 (30%)]#011Loss: 0.015861\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [18560/60000 (31%)]#011Loss: 0.013824\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [19200/60000 (32%)]#011Loss: 0.091992\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [19840/60000 (33%)]#011Loss: 0.147832\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [20480/60000 (34%)]#011Loss: 0.064117\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [21120/60000 (35%)]#011Loss: 0.043358\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [21760/60000 (36%)]#011Loss: 0.026285\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [22400/60000 (37%)]#011Loss: 0.013773\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [23040/60000 (38%)]#011Loss: 0.220991\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [23680/60000 (39%)]#011Loss: 0.013288\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [24320/60000 (41%)]#011Loss: 0.047371\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [24960/60000 (42%)]#011Loss: 0.036902\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [25600/60000 (43%)]#011Loss: 0.017076\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [26240/60000 (44%)]#011Loss: 0.012552\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [26880/60000 (45%)]#011Loss: 0.030517\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [27520/60000 (46%)]#011Loss: 0.010661\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [28160/60000 (47%)]#011Loss: 0.036297\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [28800/60000 (48%)]#011Loss: 0.038526\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [29440/60000 (49%)]#011Loss: 0.075751\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [30080/60000 (50%)]#011Loss: 0.030334\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [30720/60000 (51%)]#011Loss: 0.017933\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [31360/60000 (52%)]#011Loss: 0.018865\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [32000/60000 (53%)]#011Loss: 0.081428\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [32640/60000 (54%)]#011Loss: 0.002074\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [33280/60000 (55%)]#011Loss: 0.036812\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [33920/60000 (57%)]#011Loss: 0.092933\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [34560/60000 (58%)]#011Loss: 0.013320\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [35200/60000 (59%)]#011Loss: 0.170214\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [35840/60000 (60%)]#011Loss: 0.053073\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [36480/60000 (61%)]#011Loss: 0.002863\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [37120/60000 (62%)]#011Loss: 0.017365\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [37760/60000 (63%)]#011Loss: 0.191666\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [38400/60000 (64%)]#011Loss: 0.011246\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [39040/60000 (65%)]#011Loss: 0.005264\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [39680/60000 (66%)]#011Loss: 0.005667\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [40320/60000 (67%)]#011Loss: 0.044670\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [40960/60000 (68%)]#011Loss: 0.115487\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [41600/60000 (69%)]#011Loss: 0.082201\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [42240/60000 (70%)]#011Loss: 0.013243\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [42880/60000 (71%)]#011Loss: 0.101502\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [43520/60000 (72%)]#011Loss: 0.075403\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [44160/60000 (74%)]#011Loss: 0.089750\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [44800/60000 (75%)]#011Loss: 0.064704\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [45440/60000 (76%)]#011Loss: 0.003072\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [46080/60000 (77%)]#011Loss: 0.039818\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [46720/60000 (78%)]#011Loss: 0.086558\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [47360/60000 (79%)]#011Loss: 0.038284\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [48000/60000 (80%)]#011Loss: 0.037715\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [48640/60000 (81%)]#011Loss: 0.118890\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [49280/60000 (82%)]#011Loss: 0.014621\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [49920/60000 (83%)]#011Loss: 0.027668\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [50560/60000 (84%)]#011Loss: 0.057537\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [51200/60000 (85%)]#011Loss: 0.010682\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [51840/60000 (86%)]#011Loss: 0.138573\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [52480/60000 (87%)]#011Loss: 0.030908\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [53120/60000 (88%)]#011Loss: 0.112818\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [53760/60000 (90%)]#011Loss: 0.067318\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [54400/60000 (91%)]#011Loss: 0.009634\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [55040/60000 (92%)]#011Loss: 0.019119\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [55680/60000 (93%)]#011Loss: 0.095595\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [56320/60000 (94%)]#011Loss: 0.059340\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [56960/60000 (95%)]#011Loss: 0.003941\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [57600/60000 (96%)]#011Loss: 0.001915\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [58240/60000 (97%)]#011Loss: 0.108577\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [58880/60000 (98%)]#011Loss: 0.024358\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [59520/60000 (99%)]#011Loss: 0.005027\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0332, Accuracy: 9893/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/60000 (0%)]#011Loss: 0.004742\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [640/60000 (1%)]#011Loss: 0.003269\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [1280/60000 (2%)]#011Loss: 0.017177\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [1920/60000 (3%)]#011Loss: 0.002910\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [2560/60000 (4%)]#011Loss: 0.087438\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [3200/60000 (5%)]#011Loss: 0.146124\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [3840/60000 (6%)]#011Loss: 0.084865\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [4480/60000 (7%)]#011Loss: 0.018904\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [5120/60000 (9%)]#011Loss: 0.033643\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [5760/60000 (10%)]#011Loss: 0.011051\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [6400/60000 (11%)]#011Loss: 0.003427\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [7040/60000 (12%)]#011Loss: 0.069867\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [7680/60000 (13%)]#011Loss: 0.016611\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [8320/60000 (14%)]#011Loss: 0.011623\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [8960/60000 (15%)]#011Loss: 0.007059\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [9600/60000 (16%)]#011Loss: 0.004913\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [10240/60000 (17%)]#011Loss: 0.015835\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [10880/60000 (18%)]#011Loss: 0.014601\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [11520/60000 (19%)]#011Loss: 0.001793\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [12160/60000 (20%)]#011Loss: 0.025408\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [12800/60000 (21%)]#011Loss: 0.001909\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [13440/60000 (22%)]#011Loss: 0.020234\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [14080/60000 (23%)]#011Loss: 0.023607\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [14720/60000 (25%)]#011Loss: 0.003960\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [15360/60000 (26%)]#011Loss: 0.041389\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [16000/60000 (27%)]#011Loss: 0.077344\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [16640/60000 (28%)]#011Loss: 0.025361\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [17280/60000 (29%)]#011Loss: 0.009292\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [17920/60000 (30%)]#011Loss: 0.011747\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [18560/60000 (31%)]#011Loss: 0.059853\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [19200/60000 (32%)]#011Loss: 0.025643\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [19840/60000 (33%)]#011Loss: 0.198655\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [20480/60000 (34%)]#011Loss: 0.199354\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [21120/60000 (35%)]#011Loss: 0.164895\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [21760/60000 (36%)]#011Loss: 0.057611\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [22400/60000 (37%)]#011Loss: 0.021888\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [23040/60000 (38%)]#011Loss: 0.008036\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [23680/60000 (39%)]#011Loss: 0.043383\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [24320/60000 (41%)]#011Loss: 0.023139\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [24960/60000 (42%)]#011Loss: 0.030114\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [25600/60000 (43%)]#011Loss: 0.042002\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [26240/60000 (44%)]#011Loss: 0.108992\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [26880/60000 (45%)]#011Loss: 0.010692\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [27520/60000 (46%)]#011Loss: 0.007219\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [28160/60000 (47%)]#011Loss: 0.010162\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [28800/60000 (48%)]#011Loss: 0.006772\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [29440/60000 (49%)]#011Loss: 0.074931\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [30080/60000 (50%)]#011Loss: 0.076434\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [30720/60000 (51%)]#011Loss: 0.024813\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [31360/60000 (52%)]#011Loss: 0.028144\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [32000/60000 (53%)]#011Loss: 0.057772\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [32640/60000 (54%)]#011Loss: 0.063995\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [33280/60000 (55%)]#011Loss: 0.003258\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [33920/60000 (57%)]#011Loss: 0.032399\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [34560/60000 (58%)]#011Loss: 0.324282\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [35200/60000 (59%)]#011Loss: 0.074190\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [35840/60000 (60%)]#011Loss: 0.026413\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [36480/60000 (61%)]#011Loss: 0.059937\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [37120/60000 (62%)]#011Loss: 0.059022\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [37760/60000 (63%)]#011Loss: 0.105578\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [38400/60000 (64%)]#011Loss: 0.052450\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [39040/60000 (65%)]#011Loss: 0.040134\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [39680/60000 (66%)]#011Loss: 0.091936\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [40320/60000 (67%)]#011Loss: 0.038884\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [40960/60000 (68%)]#011Loss: 0.031436\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [41600/60000 (69%)]#011Loss: 0.027352\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [42240/60000 (70%)]#011Loss: 0.030169\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [42880/60000 (71%)]#011Loss: 0.006503\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [43520/60000 (72%)]#011Loss: 0.105376\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [44160/60000 (74%)]#011Loss: 0.079741\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [44800/60000 (75%)]#011Loss: 0.004102\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [45440/60000 (76%)]#011Loss: 0.111714\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [46080/60000 (77%)]#011Loss: 0.023616\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [46720/60000 (78%)]#011Loss: 0.005739\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [47360/60000 (79%)]#011Loss: 0.002808\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [48000/60000 (80%)]#011Loss: 0.010542\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [48640/60000 (81%)]#011Loss: 0.001196\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [49280/60000 (82%)]#011Loss: 0.239236\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [49920/60000 (83%)]#011Loss: 0.033728\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [50560/60000 (84%)]#011Loss: 0.011561\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [51200/60000 (85%)]#011Loss: 0.119502\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [51840/60000 (86%)]#011Loss: 0.028499\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [52480/60000 (87%)]#011Loss: 0.137508\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [53120/60000 (88%)]#011Loss: 0.009173\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [53760/60000 (90%)]#011Loss: 0.002652\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [54400/60000 (91%)]#011Loss: 0.147803\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [55040/60000 (92%)]#011Loss: 0.257964\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [55680/60000 (93%)]#011Loss: 0.018042\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [56320/60000 (94%)]#011Loss: 0.016691\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [56960/60000 (95%)]#011Loss: 0.042051\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [57600/60000 (96%)]#011Loss: 0.013096\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [58240/60000 (97%)]#011Loss: 0.024661\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [58880/60000 (98%)]#011Loss: 0.032174\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [59520/60000 (99%)]#011Loss: 0.006805\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0293, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-04-21 18:30:28,107 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-04-21 18:30:37 Uploading - Uploading generated training model\n",
      "2021-04-21 18:30:37 Completed - Training job completed\n",
      "Training seconds: 301\n",
      "Billable seconds: 301\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': f's3://{bucket}/mnist_data/',\n",
    "                'test': f's3://{bucket}/mnist_data/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-management",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-personal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
